{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install pycocotools\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Modules\n",
    "# --------------------------------------------------\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Torch Modules\n",
    "# --------------------------------------------------\n",
    "import torch\n",
    "import torch.nn         as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Third Party Modules\n",
    "# --------------------------------------------------\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "# Custom Modules\n",
    "# --------------------------------------------------\n",
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "\n",
    "import config\n",
    "import utils\n",
    "\n",
    "from Model import (\n",
    "    EncoderCNN, \n",
    "    DecoderRNN\n",
    ")\n",
    "\n",
    "\n",
    "# Settings\n",
    "# --------------------------------------------------\n",
    "sys.path.append(config.COCO_API_PATH)\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Image Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(config.EMBED_SIZE),                        \n",
    "    transforms.RandomCrop(config.INPUT_SIZE),                      \n",
    "    transforms.RandomHorizontalFlip(),             \n",
    "    transforms.ToTensor(),                          \n",
    "    transforms.Normalize(\n",
    "        config.IMAGENET_MU,      \n",
    "        config.IMAGENET_SIGMA\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.89s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 383/414113 [00:00<01:48, 3826.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [01:27<00:00, 4718.10it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader = utils.get_loader(\n",
    "    transform       = transform_train,\n",
    "    mode            = \"train\",\n",
    "    batch_size      = config.TRAIN_BATCH_SIZE,\n",
    "    ann_file        = config.ANN_CAPTIONS_TRAIN_FILE,\n",
    "    vocab_from_file = config.LOAD_VOCAB_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "100%|██████████| 102502400/102502400 [00:03<00:00, 27570857.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get Vocabulary Size\n",
    "# --------------------------------------------------\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "\n",
    "# Initialize Models\n",
    "# --------------------------------------------------\n",
    "encoder = EncoderCNN()\n",
    "decoder = DecoderRNN(vocab_size)\n",
    "\n",
    "\n",
    "# Move Models to Device\n",
    "# --------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "\n",
    "# Initialize Loss Function\n",
    "# -------------------------------------------------- \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Initialize Hyperparameters\n",
    "# -------------------------------------------------- \n",
    "params = list(decoder.parameters())       + \\\n",
    "         list(encoder.embed.parameters()) + \\\n",
    "         list(encoder.norm.parameters())\n",
    "\n",
    "\n",
    "# Initialize Optimizer\n",
    "# -------------------------------------------------- \n",
    "optimizer = torch.optim.Adam(params)\n",
    "\n",
    "\n",
    "# Define Training Steps\n",
    "# -------------------------------------------------- \n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open Train Log\n",
    "# --------------------------------------------------\n",
    "f = open(config.TRAIN_LOG_FILE, \"w\")\n",
    "\n",
    "\n",
    "# Initialize Time\n",
    "# --------------------------------------------------\n",
    "start_time = time.time()\n",
    "response   = requests.request(\n",
    "    \"GET\", \n",
    "    \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "    headers = {\n",
    "        \"Metadata-Flavor\" : \"Google\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Train Model\n",
    "# --------------------------------------------------    \n",
    "for epoch in range(1, config.TRAIN_EPOCHS + 1):\n",
    "    for i_step in range(1, total_step + 1):\n",
    "        if time.time() - start_time > 60:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            requests.request(\n",
    "                \"POST\", \n",
    "                \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                headers = {\n",
    "                    \"Authorization\": \"STAR \" + response.text\n",
    "                })\n",
    "\n",
    "\n",
    "        # Sample Captions by Length to Generate Batch\n",
    "        # --------------------------------------------------\n",
    "        indices     = data_loader.dataset.get_train_indices()\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices = indices)\n",
    "\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        images, captions                  = next(iter(data_loader))\n",
    "\n",
    "\n",
    "        # Move Batch to Training Device\n",
    "        # --------------------------------------------------\n",
    "        images   = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "\n",
    "\n",
    "        # Zero Gradients\n",
    "        # --------------------------------------------------\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "\n",
    "\n",
    "        # Send Inputs to Encoder and Decoder\n",
    "        # --------------------------------------------------\n",
    "        features = encoder(images)\n",
    "        outputs  = decoder(features, captions)\n",
    "\n",
    "\n",
    "        # Calculate Loss\n",
    "        # --------------------------------------------------\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "\n",
    "\n",
    "        # Update Weights\n",
    "        # --------------------------------------------------\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Get Training Statistics\n",
    "        # --------------------------------------------------\n",
    "        stats = (\n",
    "            f\"--------------------------------------------------\\n\"\n",
    "            f\"Epoch:      [{epoch}/{config.TRAIN_EPOCHS}]\\n\"\n",
    "            f\"Step:       [{i_step}/{total_step}]\\n\"\n",
    "            f\"Loss:       {round(loss.item(), 4)}\\n\"\n",
    "            f\"Perplexity: {round(np.exp(loss.item()), 5)}\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "        # Print Stats to Console\\\n",
    "        # --------------------------------------------------\n",
    "        print(\"\\r\" + stats, end = \"\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if i_step % config.TRAIN_PRINT_FREQ == 0:\n",
    "            print(\"\\r\" + stats)\n",
    "\n",
    "\n",
    "        # Save Stats to Logs\n",
    "        # --------------------------------------------------\n",
    "        f.write(stats + \"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "\n",
    "    # Save Epoch Weights\n",
    "    # --------------------------------------------------\n",
    "    if epoch % config.TRAIN_SAVE_FREQ == 0:\n",
    "        torch.save(decoder.state_dict(), f\"{config.MODEL_DIR}/decoder-{epoch}.pkl\")\n",
    "        torch.save(encoder.state_dict(), f\"{config.MODEL_DIR}/encoder-{epoch}.pkl\")\n",
    "\n",
    "\n",
    "# Close Train Log\n",
    "# --------------------------------------------------\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
